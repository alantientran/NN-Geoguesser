{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37fdb2bb",
   "metadata": {},
   "source": [
    "# üåç GeoViT: A Convolutional-Transformer Model for Geolocation Estimation\n",
    "\n",
    "Welcome to the GeoViT project notebook!\n",
    "\n",
    "This notebook presents the training, evaluation, and experimentation pipeline for **GeoViT**, a neural network model designed to **predict geographic locations from Google Street View images**. The model takes inspiration from the popular game *Geoguessr* and is trained using the [OpenStreetView-5M dataset](https://huggingface.co/datasets/osv5m/osv5m).\n",
    "\n",
    "üñäÔ∏è Authors: Alan Tran and Caleb Wolf\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Project Goals\n",
    "\n",
    "1. **Train** a hybrid convolutional-transformer model that can learn geospatial patterns from street-level imagery.\n",
    "2. **Evaluate** the model using geodesic distance-based metrics.\n",
    "3. **Experiment** with:\n",
    "   - Vision Transformer ablations (layers & attention heads)\n",
    "   - Robustness to reduced image context (square vs 3:2 aspect ratio)\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Model Overview\n",
    "\n",
    "- **Convolutional Frontend:** Captures local texture and object-level features.\n",
    "- **Vision Transformer (ViT):** Captures global spatial dependencies.\n",
    "- **Output:** Regressed GPS coordinates (Latitude, Longitude)\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Experiments\n",
    "\n",
    "### ‚úÖ Experiment 1: ViT Ablation\n",
    "- Reduce number of transformer layers and attention heads\n",
    "- Assess contribution of transformer structure to geolocation performance\n",
    "\n",
    "### ‚úÖ Experiment 2: Robustness to Cropped Context\n",
    "- Evaluate model on square images (less context)\n",
    "- Compare against standard aspect ratio input\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2187ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from s2sphere import LatLng, CellId\n",
    "import heapq\n",
    "import csv\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9161358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that maps cells to grid indices\n",
    "class Region:\n",
    "    __slots__ = ('cell_id','level','indices')\n",
    "    def __init__(self, cell_id, level, indices):\n",
    "        self.cell_id = cell_id      # an s2sphere.CellId\n",
    "        self.level   = level        # integer level\n",
    "        self.indices = indices      # list of DataFrame indices\n",
    "    def count(self): \n",
    "        return len(self.indices)\n",
    "    def split(self, df, lat_col, lon_col):\n",
    "        \"\"\"Split into children at level+1 and group membership.\"\"\"\n",
    "        next_level = self.level + 1\n",
    "        groups = {}\n",
    "        for i in self.indices:\n",
    "            lat, lon = df.at[i, lat_col], df.at[i, lon_col]\n",
    "            cid = CellId.from_lat_lng(LatLng.from_degrees(lat, lon)) \\\n",
    "                         .parent(next_level)\n",
    "            groups.setdefault(cid.id(), []).append(i)\n",
    "        return [\n",
    "            Region(CellId(child_id), next_level, idxs)\n",
    "            for child_id, idxs in groups.items()\n",
    "        ]\n",
    "\n",
    "def build_planet_partitions(\n",
    "    train_df: pd.DataFrame,\n",
    "    lat_col: str = 'latitude',\n",
    "    lon_col: str = 'longitude',\n",
    "    t1: int = 10000,\n",
    "    t2: int = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs PlaNet‚Äêstyle adaptive partitioning on train_df,\n",
    "    returns (labels, kept_regions):\n",
    "      - labels: pd.Series of length train_df, with class 0‚Ä¶K-1 (or -1)\n",
    "      - kept_regions: list of Region objects whose cells were kept (count >= t2)\n",
    "    \"\"\"\n",
    "    # 1) Seed with level=0 roots\n",
    "    root_ids = train_df.apply(\n",
    "        lambda r: CellId\n",
    "            .from_lat_lng(LatLng.from_degrees(r[lat_col], r[lon_col]))\n",
    "            .parent(0)\n",
    "            .id(),\n",
    "        axis=1\n",
    "    )\n",
    "    roots = [\n",
    "        Region(CellId(rid), 0, idxs.tolist())\n",
    "        for rid, idxs in root_ids.groupby(root_ids).groups.items()\n",
    "    ]\n",
    "\n",
    "    # 2) Recursively split any region > t1\n",
    "\n",
    "    # include cell_id.id() as a tie-breaker\n",
    "    heap = [(-r.count(),  r.cell_id.id(),  r) for r in roots]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    leaves = []\n",
    "    while heap:\n",
    "        negc, _, region = heapq.heappop(heap)\n",
    "        if region.count() > t1:\n",
    "            for child in region.split(train_df, lat_col, lon_col):\n",
    "                # push with the same tuple structure\n",
    "                heapq.heappush(heap, (-child.count(), child.cell_id.id(), child))\n",
    "        else:\n",
    "            leaves.append(region)\n",
    "\n",
    "    # 3) Prune leaves < t2\n",
    "    kept = [r for r in leaves if r.count() >= t2]\n",
    "\n",
    "    # 4) Assign train labels\n",
    "    train_labels = pd.Series(-1, index=train_df.index, dtype=int)\n",
    "    for cls_idx, region in enumerate(kept):\n",
    "        train_labels.loc[region.indices] = cls_idx\n",
    "\n",
    "    return train_labels, kept\n",
    "\n",
    "def assign_planet_labels(\n",
    "    df: pd.DataFrame,\n",
    "    regions: list,\n",
    "    lat_col: str = 'latitude',\n",
    "    lon_col: str = 'longitude',\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given any df and a list of kept Region objects (from build_planet_partitions),\n",
    "    returns a pd.Series of ‚Äì1 or 0‚Ä¶K-1 depending on which region each point falls into.\n",
    "    \"\"\"\n",
    "    # Group regions by their level for faster lookup\n",
    "    by_level = {}\n",
    "    for cls_idx, reg in enumerate(regions):\n",
    "        by_level.setdefault(reg.level, {})[reg.cell_id.id()] = cls_idx\n",
    "\n",
    "    labels = pd.Series(-1, index=df.index, dtype=int)\n",
    "\n",
    "    # For each unique level, compute all cell_ids in bulk and map\n",
    "    for level, mapping in by_level.items():\n",
    "        # compute cell_id.id() at this level for every point\n",
    "        ids = df.apply(\n",
    "            lambda r: CellId\n",
    "                .from_lat_lng(LatLng.from_degrees(r[lat_col], r[lon_col]))\n",
    "                .parent(level)\n",
    "                .id(),\n",
    "            axis=1\n",
    "        )\n",
    "        # map to class_idx (NaN becomes -1)\n",
    "        mapped = ids.map(mapping).fillna(-1).astype(int)\n",
    "        # only overwrite labels that are still -1\n",
    "        mask = (labels == -1) & (mapped >= 0)\n",
    "        labels.loc[mask] = mapped.loc[mask]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a625a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "DATA_ROOT = 'osv5m/'\n",
    "TRAIN_CSV = os.path.join(DATA_ROOT, 'train_mini.csv')\n",
    "TEST_CSV = os.path.join(DATA_ROOT, 'test_mini.csv')\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_ROOT, 'train_images')\n",
    "TEST_IMG_DIR = os.path.join(DATA_ROOT, 'test_images')\n",
    "\n",
    "# Set global parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "L = 10\n",
    "LABEL_COL = 'planet_class'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Read CSV files\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Build partitions on train and test\n",
    "train_labels, kept_regions = build_planet_partitions(\n",
    "    train_df, lat_col='latitude', lon_col='longitude',\n",
    "    t1=100, t2=20\n",
    ")\n",
    "train_df[LABEL_COL] = train_labels\n",
    "train_df = train_df[train_labels >= 0].reset_index(drop=True)\n",
    "\n",
    "test_labels = assign_planet_labels(\n",
    "    test_df, kept_regions, lat_col='latitude', lon_col='longitude'\n",
    ")\n",
    "test_df[LABEL_COL] = test_labels\n",
    "test_df = test_df[test_labels >= 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a2b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 88 668 884 311 985]\n",
      "2199\n"
     ]
    }
   ],
   "source": [
    "print(train_df[LABEL_COL].unique()[:5])\n",
    "print(train_df[LABEL_COL].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23799d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN + ViT hybrid model for geospatial classification\n",
    "class CNN_ViT_Hybrid(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Conv feature extractor (ResNet50)\n",
    "        self.cnn = timm.create_model(\"resnet50\", pretrained=True, features_only=True)\n",
    "        cnn_out_channels = self.cnn.feature_info[-1]['num_chs']\n",
    "\n",
    "        # ViT block (tiny patch-based attention)\n",
    "        self.vit = timm.create_model(\"vit_small_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()  # remove classifier\n",
    "\n",
    "        # Fusion + Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d((14, 14))\n",
    "        self.proj = nn.Linear(cnn_out_channels, self.vit.embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2) # Dropout Regularization\n",
    "        self.classifier = nn.Linear(self.vit.embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get last feature map from CNN\n",
    "        x = self.cnn(x)[-1]  # shape (B, C, H, W)\n",
    "\n",
    "        # Pool to fixed 14 x 14 size\n",
    "        x = self.pool(x)  # shape (B, C, 14, 14)\n",
    "\n",
    "        # Flatten and transpose to patch seq format that matches ViT input\n",
    "        x = x.flatten(2).transpose(1, 2)  # (B, C, H*W) -> (B, H*W, C)\n",
    "\n",
    "        # Project to ViT embedding dim\n",
    "        x = self.proj(x)  # shape (B, 196, D)\n",
    "\n",
    "        # Feed through ViT encoder blocks\n",
    "        x = self.vit.blocks(x)\n",
    "        x = x.mean(dim=1)  # Global average pooling\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.classifier(x)\n",
    "    \n",
    "# Define the geospatial dataset class\n",
    "class GeoDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        images_root: str,\n",
    "        nclasses: int,\n",
    "        label_col: str = 'planet_class',\n",
    "        transforms=None\n",
    "    ):\n",
    "        # 1) keep only valid labels (>=0)\n",
    "        self.df = df[df[label_col] >= 0].reset_index(drop=True)\n",
    "\n",
    "        self.label_col = label_col\n",
    "        self.classes = nclasses\n",
    "\n",
    "        # 3) build a map from image‚ÄêID ‚Üí full path\n",
    "        all_files = glob.glob(os.path.join(images_root, '*', '*.jpg'))\n",
    "        self.id2path = {\n",
    "            os.path.splitext(os.path.basename(p))[0]: p\n",
    "            for p in all_files\n",
    "        }\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row    = self.df.iloc[idx]\n",
    "        img_id = str(row['id'])\n",
    "        label  = int(row[self.label_col])\n",
    "        img    = Image.open(self.id2path[img_id]).convert('RGB')\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24172788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax size (num classes) = 2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alan\\anaconda3\\envs\\NN1\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transformations for training data augmentation (better generalization)\n",
    "train_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02)\n",
    "    ], p=0.5),  # apply 50% of the time variations in color (simulates lighting changes)\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "# Transformations for test data (no augmentation)\n",
    "test_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Instantiate the dataset and dataloaders\n",
    "train_ds = GeoDataset(\n",
    "    df          = train_df,\n",
    "    images_root = TRAIN_IMG_DIR,\n",
    "    label_col   = LABEL_COL,\n",
    "    nclasses=len(kept_regions),\n",
    "    transforms  = train_transforms\n",
    ")\n",
    "\n",
    "test_ds = GeoDataset(\n",
    "    df          = test_df,\n",
    "    images_root = TEST_IMG_DIR,\n",
    "    label_col   = LABEL_COL,\n",
    "    nclasses=len(kept_regions),\n",
    "    transforms  = test_transforms\n",
    ")\n",
    "\n",
    "print(f\"Softmax size (num classes) = {train_ds.classes}\")  # same for both\n",
    "\n",
    "num_val = int(0.1 * len(train_ds)) # 90% training set, 10% testing set\n",
    "num_train = len(train_ds) - num_val\n",
    "train_subset, val_subset = random_split(train_ds, [num_train, num_val], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_subset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,      batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model\n",
    "model = CNN_ViT_Hybrid(num_classes=train_ds.classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Freeze ResNet\n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Freeze ViT\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create optimizer only for trainable layers (ViT projection + classifier)\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=1e-4, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,   # reduce LR by half\n",
    "    patience=2,   # wait 2 epochs with no val loss improvement\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "889c7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Get dimensions of training batch\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fcd2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a6e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 25/1583 [00:28<28:41,  1.10s/it]"
     ]
    }
   ],
   "source": [
    "log_file = open(\"training_log.csv\", mode=\"w\", newline=\"\")\n",
    "logger = csv.writer(log_file)\n",
    "logger.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"lr\"])\n",
    "\n",
    "# TensorBoard writer for visualizing metrics\n",
    "writer = SummaryWriter(\"runs/geo_model_experiment\")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float('inf')\n",
    "# --- Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nüåç Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    # Unfreeze layers after 3 epochs\n",
    "    if epoch == 3:\n",
    "        print(\"üîì Unfreezing layers...\")\n",
    "        for param in model.cnn.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.vit.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()), \n",
    "            lr=1e-5,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc     = evaluate(model, val_loader)\n",
    "\n",
    "    # Log scheduler learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Current learning rate: {param_group['lr']}\")\n",
    "\n",
    "    # Save metrics to CSV file\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    logger.writerow([epoch+1, train_loss, train_acc, val_loss, val_acc, current_lr])\n",
    "    log_file.flush()  # ensures it's written to disk\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        writer.add_scalar(\"Learning Rate\", param_group['lr'], epoch)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss or val_acc > best_val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f\"hybrid_best_model_epoch{epoch+1}.pth\")\n",
    "        print(\"‚úÖ Saved best model.\")\n",
    "\n",
    "log_file.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed6465",
   "metadata": {},
   "source": [
    "After training, go to the terminal bash and run: tensorboard --logdir=runs\n",
    "in order to see visualizations. Then go to http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437872f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Test ---\n",
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"\\n‚úÖ Final Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
